{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Method 4(b): GAMA using DWave quantum annealer"
      ],
      "metadata": {
        "id": "o7_88dQ8WUDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTMiJU2pUnAw"
      },
      "outputs": [],
      "source": [
        "!pip install dimod\n",
        "!pip install dwave-neal\n",
        "!pip install dwave-ocean-sdk\n",
        "!pip install kaggle\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dwave packages dimod and neal\n",
        "import dimod\n",
        "import neal\n",
        "# Import Matplotlib to generate plots\n",
        "import matplotlib.pyplot as plt\n",
        "# Import other necessary libraries\n",
        "import numpy as np\n",
        "from scipy.special import gamma\n",
        "import math\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "import time\n",
        "import networkx as nx\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "from os import listdir\n",
        "from numpy import save\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array"
      ],
      "metadata": {
        "id": "wokKZEp6UziK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "NUL7nrAnVvj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download pcbreviglieri/pneumonia-xray-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn9dDRhgWOCX",
        "outputId": "f2feeb71-c513-4a0b-8955-74707e67dd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pneumonia-xray-images.zip to /content\n",
            " 99% 1.13G/1.14G [00:16<00:00, 73.6MB/s]\n",
            "100% 1.14G/1.14G [00:16<00:00, 74.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip pneumonia-xray-images\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "GImyhmzQWTEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize opacity images from training set\n",
        "\n",
        "folder = '/content/train/opacity'\n",
        "photos_op1 = list()\n",
        "\n",
        "n1 = 200\n",
        "n2 = 200\n",
        "\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "    # load image\n",
        "    photo = load_img( '/content/train/opacity/'+ file, target_size=(n1, n2), color_mode='grayscale')\n",
        "    # convert to numpy array\n",
        "    photo = img_to_array(photo)\n",
        "    # store in the list of photos\n",
        "    photos_op1.append(photo)\n",
        "\n",
        "# convert list of photos and labels to numpy arrays\n",
        "photos_op = np.array(photos_op1[:1000])\n",
        "\n",
        "# label = -1 for opacity cases\n",
        "labels_op = np.array([-1.0]*1000)\n",
        "\n",
        "op_train = list()\n",
        "for i in range(1000):\n",
        "  op_train.append(photos_op[i].reshape(-1))\n",
        "op_train = np.array(op_train)\n",
        "op_train = op_train/255.0\n",
        "\n",
        "print(op_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McgGsjUsWZ02",
        "outputId": "cb15fde2-df90-4a5b-c11b-c51c8351dd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 40000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resize normal images from training set\n",
        "folder = '/content/train/normal'\n",
        "photos_no = list()\n",
        "\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "    # load image\n",
        "    photo = load_img( '/content/train/normal/'+ file, target_size=(n1, n2), color_mode='grayscale')\n",
        "    # convert to numpy array\n",
        "    photo = img_to_array(photo)\n",
        "    # store in the list of photos\n",
        "    photos_no.append(photo)\n",
        "\n",
        "# convert list of photos and labels to numpy arrays\n",
        "photos_no = np.array(photos_no[:1000])\n",
        "\n",
        "# label = +1 for normal cases\n",
        "labels_no = np.array([1.0]*1000)\n",
        "\n",
        "no_train = list()\n",
        "for i in range(1000):\n",
        "  no_train.append(photos_no[i].reshape(-1))\n",
        "no_train = np.array(no_train)\n",
        "no_train = no_train/255.0\n",
        "\n",
        "print(no_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3vtEDSWdAY",
        "outputId": "e66a6a33-b2e4-45b5-83a5-86536c5067d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 40000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for normal case images in test data set\n",
        "folder = '/content/val/normal'\n",
        "photos_test_no = list()\n",
        "\n",
        "# enumerate files in the directory\n",
        "for file in listdir(folder):\n",
        "    # load image\n",
        "    photo = load_img( '/content/val/normal/'+ file, target_size=(n1, n2), color_mode='grayscale')\n",
        "    # convert to numpy array\n",
        "    photo = img_to_array(photo)\n",
        "    # store in the list of photos\n",
        "    photos_test_no.append(photo)\n",
        "\n",
        "# convert list of photos and labels to numpy arrays\n",
        "photos_test_no = np.array(photos_test_no)\n",
        "\n",
        "# label = +1 for normal cases\n",
        "labels_test_no = np.array([1.0]*photos_test_no.shape[0])\n",
        "\n",
        "no_test = list()\n",
        "for i in range(267):\n",
        "  no_test.append(photos_test_no[i].reshape(-1))\n",
        "no_test = np.array(no_test)\n",
        "no_test = no_test/255.0\n",
        "\n",
        "print(no_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "079BHPbQWfb1",
        "outputId": "f0018e21-8ef8-4c86-be53-371b498e1154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(267, 40000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for opacity case test data take extra images from train folder that are not used for training\n",
        "\n",
        "# convert list of photos and labels to numpy arrays\n",
        "photos_test_op = np.array(photos_op1[1000:2000])\n",
        "\n",
        "# label = -1 for normal cases\n",
        "labels_test_op = np.array([-1.0]*photos_test_op.shape[0])\n",
        "\n",
        "op_test = list()\n",
        "for i in range(1000):\n",
        "  op_test.append(photos_test_op[i].reshape(-1))\n",
        "op_test = np.array(op_test)\n",
        "op_test = op_test/255.0\n",
        "\n",
        "print(op_test.shape)"
      ],
      "metadata": {
        "id": "VUyl-5KaWiZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e75327-cae2-4b85-f136-0ce2c4c0b1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 40000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide all images and labels in sets of 50 each\n",
        "train = np.empty((40, 50, 40000))\n",
        "lab = np.empty((40, 50))\n",
        "for i in range(40):\n",
        "    train[i] = np.append(op_train[25*i:25*(i+1)], no_train[25*i:25*(i+1)], axis = 0)\n",
        "    lab[i] = np.append(labels_op[25*i:25*(i+1)], labels_no[25*i:25*(i+1)])\n",
        "\n",
        "print(train.shape, lab.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_PEscWIWxby",
        "outputId": "93f8b62f-b84d-473a-f92e-3955c7522386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 50, 40000) (40, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define RBF kernel\n",
        "import math\n",
        "def Kernel(mat1, mat2, sigma):\n",
        "  norm=np.linalg.norm(mat1-mat2)\n",
        "  k = -(0.5*norm**2)/(sigma**2)\n",
        "  return np.exp(k)"
      ],
      "metadata": {
        "id": "Pp8iyFboWznK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate kernel matrix for all image sets\n",
        "# kern is the list of all 40 kernel matrices\n",
        "kern=list()\n",
        "for k in range(40):\n",
        "  a = np.empty((50,50))\n",
        "  for i in range(50):\n",
        "    for j in range(50):\n",
        "      a[i][j]=Kernel(train[k][i],train[k][j],50)\n",
        "  kern.append(a)\n",
        "kern = np.array(kern)"
      ],
      "metadata": {
        "id": "SDId5nE_W3Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since the contraint equation is same for all sets, we have only one QUBO\n",
        "I = np.identity(50)\n",
        "p = [1,2]\n",
        "E = np.kron(I,p)\n",
        "\n",
        "YY = np.outer(lab[0], lab[0])\n",
        "\n",
        "Q = np.matmul(np.matmul(E.T, YY), E)"
      ],
      "metadata": {
        "id": "VIMA_vR-W8bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dwave-ocean-sdk\n",
        "!dwave setup\n",
        "!dwave ping"
      ],
      "metadata": {
        "id": "HpTbCb3D3NMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xbvn9l7y0p5"
      },
      "source": [
        "import dwave_networkx as dnx\n",
        "from dwave.system import (DWaveSampler, EmbeddingComposite,\n",
        "                          FixedEmbeddingComposite)\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solve the QUBO on DWave quantum annealer\n",
        "model = dimod.BinaryQuadraticModel.from_qubo(Q)\n",
        "DWavesampler = EmbeddingComposite(DWaveSampler(solver='Advantage_system6.2'))\n",
        "DWaveSamples = DWavesampler.sample(bqm=model, num_reads=1000,\n",
        "                                   return_embedding=True,\n",
        "                                  #  chain_strength=chain_strength,\n",
        "                                  #  annealing_time=annealing_time\n",
        "                                   )\n",
        "\n",
        "X1 = np.array([[ 0 for j in range(100)] for k in range(1000)])\n",
        "m = 0\n",
        "\n",
        "# saving parameter values that give zero energy\n",
        "for sample,energy, num_occ in DWaveSamples.data(['sample','energy','num_occurrences']):\n",
        "    if (energy == 0):\n",
        "        X1[m] = list(sample.values())\n",
        "        m=m+1\n",
        "\n",
        "#find the unique solutions\n",
        "X1 = np.unique(X1, axis = 0)\n",
        "indices = list()\n",
        "for l in range(len(X1)):\n",
        "    for j in range(len(X1)):\n",
        "        m = 0\n",
        "        if (l == j):\n",
        "            m = 1\n",
        "        else:\n",
        "            for k in range(100):\n",
        "                if (X1[l,k] >= X1[j,k]):\n",
        "                    m += 1\n",
        "        if (m == 0):\n",
        "            indices.append(l)\n",
        "            break\n",
        "s = np.delete(X1,indices,0)"
      ],
      "metadata": {
        "id": "dQue4VOUgg3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total graver elements:', len(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8OEF4NKa4bD",
        "outputId": "f444ccfb-7a09-4e2b-f65b-d3e15eda1744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total graver elements: 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *\n",
        "from typing import Callable\n",
        "import itertools\n",
        "import random"
      ],
      "metadata": {
        "id": "Y14uGhCqhEKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define rules to choose augmentation element. Here we use the greedy approach\n",
        "def greedy(iterable):\n",
        "    for i, val in enumerate(iterable):\n",
        "        if val[1] != 0:\n",
        "            return i, val\n",
        "    else:\n",
        "        return i, val"
      ],
      "metadata": {
        "id": "oO_dgk4zmkjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can just have a single step move (works well with greedy approach)\n",
        "def single_move(i: int, g: np.ndarray, fun: Callable, x: np.ndarray, x_lo: np.ndarray = None, x_up: np.ndarray = None, laststep: np.ndarray = None) -> (float, int):\n",
        "    if x_lo is None:\n",
        "        x_lo = np.zeros_like(x)\n",
        "    if x_up is None:\n",
        "        x_up = np.ones_like(x)*max(x)*2\n",
        "\n",
        "    alpha = 0\n",
        "\n",
        "    if (x + g <= x_up).all() and (x + g >= x_lo).all():\n",
        "        if fun(x + g, i) < fun(x, i):\n",
        "            alpha = 1\n",
        "    elif (x - g <= x_up).all() and (x - g >= x_lo).all():\n",
        "        if fun(x - g, i) < fun(x, i) and fun(x - g, i) < fun(x + g, i):\n",
        "            alpha = -1\n",
        "\n",
        "    return (fun(x + alpha*g, i), alpha)"
      ],
      "metadata": {
        "id": "hmG8ucvKtBPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.zeros(100)\n",
        "x_lo = np.zeros(100)\n",
        "x_up = np.ones(100)"
      ],
      "metadata": {
        "id": "BwKhCplWtEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective function definition\n",
        "def f(x_in, i):\n",
        "    term1 = -np.sum(np.matmul(E, x_in))\n",
        "    term2 = 0.5*np.matmul(np.matmul(x_in.T, E.T), np.matmul(np.multiply(np.matmul(kern[i].T, kern[i]), YY), np.matmul(E, x_in)))\n",
        "    return term1+term2\n",
        "\n",
        "# Constraints definition\n",
        "def const(x_in):\n",
        "    rhs = np.zeros(50)\n",
        "    return np.array_equiv(np.dot(np.matmul(E, x_in), lab[0]),rhs.T) or np.array_equiv(np.dot(np.matmul(E, x_in), lab[0]),rhs)"
      ],
      "metadata": {
        "id": "bfCU95gwtMjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ktVlRUQv7Rag"
      },
      "source": [
        "def augmentation(i=0,grav = s, func = f, x = x0, x_lo = x_lo, x_up = x_up, OPTION: int = 3, VERBOSE: bool = True, itermax: int = 1000) -> (int, float, np.ndarray):\n",
        "    # Let's perform the augmentation and return the number of steps and the best solution\n",
        "    # OPTION = 1 # Best augmentation, select using bisection rule\n",
        "    # OPTION = 2 # Greedy augmentation, select using bisection rule\n",
        "    # OPTION = 3 # Greedy augmentation, select using first found\n",
        "\n",
        "    dist = 1\n",
        "    gprev = None\n",
        "    k = 1\n",
        "    if VERBOSE:\n",
        "        print(\"Initial point:\", x)\n",
        "        print(\"Objective function:\",func(i,x))\n",
        "    while dist != 0 and k < itermax:\n",
        "        if OPTION == 1:\n",
        "            g1, (obj, dist) = argmin(\n",
        "                bisection(g=e, fun=func, x=x, laststep=gprev, x_lo=x_lo, x_up=x_up) for e in grav)\n",
        "        elif OPTION == 2:\n",
        "            g1, (obj, dist) = greedy(\n",
        "                bisection(g=e, fun=func, x=x, laststep=gprev, x_lo=x_lo, x_up=x_up) for e in grav)\n",
        "        elif OPTION == 3:\n",
        "            g1, (obj, dist) = greedy(\n",
        "                single_move(i,g=e, fun=func, x=x, x_lo=x_lo, x_up=x_up) for e in grav)\n",
        "        else:\n",
        "            print(\"Option not implemented\")\n",
        "            break\n",
        "        x = x + grav[g1]*dist\n",
        "        gprev = grav[g1]\n",
        "        if VERBOSE:\n",
        "            print(\"Iteration \", k)\n",
        "            print(g1, (obj, dist))\n",
        "            print(\"Augmentation direction:\", gprev)\n",
        "            print(\"Distanced moved:\", dist)\n",
        "            print(\"Step taken:\", grav[g1]*dist)\n",
        "            print(\"Objective function:\", obj)\n",
        "            print(func(x))\n",
        "            print(\"Current point:\", x)\n",
        "            print(\"Are constraints satisfied?\", const(x))\n",
        "        else:\n",
        "            if k%50 == 0:\n",
        "                print(k)\n",
        "                print(obj)\n",
        "        k += 1\n",
        "    return(k,obj,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I = np.identity(50)\n",
        "p = [1,2]\n",
        "E = np.kron(I,p)\n",
        "\n",
        "YY = np.outer(lab[0], lab[0])\n",
        "\n",
        "Q = np.matmul(np.matmul(E.T, YY), E)"
      ],
      "metadata": {
        "id": "lsNJoNFkhoU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "7v4cBoqZkZA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b14c178-5e58-4230-b279-73fbc58ab978"
      },
      "source": [
        "# taking all graver elements\n",
        "t4=0\n",
        "feas_sols=s\n",
        "print(np.array(feas_sols).shape)\n",
        "init_obj = np.zeros((len(feas_sols),1))\n",
        "iters_few = np.zeros((len(feas_sols),1))\n",
        "final_obj_few = np.zeros((len(feas_sols),1))\n",
        "times_few = np.zeros((len(feas_sols),1))\n",
        "lagrange=list()\n",
        "for j in range(40):\n",
        " #lagrange.append(list())\n",
        " for i, sol in enumerate(feas_sols):\n",
        "    #if not const(sol):\n",
        "        #print(\"Infeasible\")\n",
        "        #pass\n",
        "    start = time.process_time()\n",
        "    iter, f_obj, xf = augmentation(j,grav = s, x = sol, func = f, OPTION=3,VERBOSE=False)\n",
        "    times_few[i] = time.process_time() - start\n",
        "    iters_few[i] = iter\n",
        "    final_obj_few[i] = f_obj\n",
        "    t4=t4+times_few[i]\n",
        " for k in range(len(feas_sols)):\n",
        "    if (final_obj_few[k]==min(final_obj_few)):\n",
        "        lagrange.append(feas_sols[k])\n",
        "        break\n",
        "#print('total augmentation time using all graver element',t4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lagrange=np.array(lagrange)"
      ],
      "metadata": {
        "id": "bs_-_tbph-Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU_rScapYFnw"
      },
      "source": [
        "xa=list()\n",
        "for i in range(40):\n",
        "  xa.append(np.matmul(E,lagrange[i].T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNTaqpFyKjkW"
      },
      "source": [
        "# calculate bias for each SVM\n",
        "bias=list()\n",
        "for i in range(40):\n",
        " b=0\n",
        " c=0\n",
        " for n in range(50):\n",
        "   a=0\n",
        "   for m in range(50):\n",
        "    a=a+xa[i][m]*lab[i][m]*kern[i][m][n]\n",
        "   b=b+xa[i][n]*(3-xa[i][n])*(lab[i][n]-a)\n",
        "   c=c+xa[i][n]*(3-xa[i][n])\n",
        " b = b/c\n",
        " bias.append(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(bias))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_-iRJ55kic3",
        "outputId": "254161df-ba87-417b-8eb3-5afec77f5fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEY5I2b6XsXT"
      },
      "source": [
        "# testing for normal test images\n",
        "yy=list()\n",
        "for i in range(267):\n",
        "    a=0.00\n",
        "    tes=list()\n",
        "    for j in range(40):\n",
        "        for k in range(50):\n",
        "                a=a+xa[j][k]*lab[j][k]*Kernel(no_test[i],train[j][k],50)\n",
        "        a=a+bias[j]\n",
        "        if a<0:\n",
        "         tes.append(-1)\n",
        "        else:\n",
        "         tes.append(1)\n",
        "        yy.append(max(set(tes), key=tes.count))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count for normal images\n",
        "a=0\n",
        "for i in range(267):\n",
        "  if yy[i]==1:\n",
        "    a=a+1\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262f1320-bd73-4337-ee7b-e02b2845d31f",
        "id": "t-IShzI9Xxuj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn5jnrE_XbtO"
      },
      "source": [
        "# testing for opacity test images\n",
        "yy=list()\n",
        "for i in range(1000):\n",
        "    a=0.00\n",
        "    tes=list()\n",
        "    for j in range(40):\n",
        "        for k in range(50):\n",
        "                a=a+xa[j][k]*lab[j][k]*Kernel(op_test[i],train[j][k],50)\n",
        "        a=a+bias[j]\n",
        "        if a<0:\n",
        "         tes.append(-1)\n",
        "        else:\n",
        "         tes.append(1)\n",
        "        yy.append(max(set(tes), key=tes.count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count for opacity images\n",
        "a=0\n",
        "for i in range(1000):\n",
        "  if yy[i]==-1:\n",
        "    a=a+1\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f060bb34-bb0c-44d9-a9c9-3beefb5a5c92",
        "id": "ju_UwweLXgv-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875\n"
          ]
        }
      ]
    }
  ]
}